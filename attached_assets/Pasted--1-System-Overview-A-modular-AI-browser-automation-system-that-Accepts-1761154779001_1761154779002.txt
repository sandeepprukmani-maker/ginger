

---

## üß† 1. System Overview

A **modular AI browser automation system** that:

* Accepts natural language commands.
* Translates them into browser actions using `browser-use` (LLM + Playwright).
* Monitors and logs every step.
* Provides a visual and replayable record of the automation.

---

## ‚öôÔ∏è 2. Core Components

| Component                          | Role                                                                   | Key Tech                                   |
| ---------------------------------- | ---------------------------------------------------------------------- | ------------------------------------------ |
| **Frontend Web App**               | UI for task creation, chat, logs, and timeline visualization           | React / Next.js + Tailwind CSS + WebSocket |
| **Backend API Layer**              | Accepts tasks, manages automation sessions, communicates with frontend | FastAPI or Flask                           |
| **Automation Engine**              | Executes tasks using LLM reasoning and Playwright                      | `browser-use` package                      |
| **Database**                       | Stores tasks, logs, and metadata                                       | PostgreSQL or SQLite                       |
| **Storage System**                 | Stores screenshots, downloads, and action logs                         | Local FS or S3                             |
| **Queue/Worker System (optional)** | For concurrent task execution                                          | Celery + Redis                             |
| **LLM Model (reasoning layer)**    | Handles ambiguous instruction clarification                            | GPT-5 / OpenAI API / local LLM             |

---

## üß© 3. Core Workflow (End-to-End)

1. **User Input:**

   * User enters natural language instruction.
   * Optional settings: headless/headful mode, context reuse, authentication info.

2. **Backend Processing:**

   * Backend validates and queues the instruction.
   * A task session is created in DB with `pending` status.
   * Backend spawns an **Automation Agent** using `browser-use`.

3. **Automation Engine Execution:**

   * `browser-use` interprets the instruction using its reasoning loop.
   * Executes actions via Playwright (clicks, typing, downloads, etc.).
   * Monitors state and auto-stops when goal is achieved.
   * Emits structured event logs for each step:

     * action type
     * description
     * page URL
     * optional screenshot
     * timestamp

4. **Frontend Updates:**

   * Events are streamed to the client (WebSocket).
   * User sees real-time progress and timeline visualization.

5. **Task Completion:**

   * Agent signals completion or failure.
   * Backend updates task status, saves final summary, and artifacts (downloads, screenshots).
   * User can view, replay, or clone the task later.

---

## üß± 4. Subsystem Breakdown

### **A. Task Management**

* **Task table schema** includes:

  * id, user_id
  * natural_language_instruction
  * execution_status (running/completed/failed)
  * start_time, end_time
  * logs (JSON)
  * final_state (summary)
  * headless/headful mode
  * browser_session_id (if persistent)

* **Operations:**

  * Create new task
  * Retrieve history
  * Replay or clone existing task
  * Export logs/screenshots as ZIP

---

### **B. Browser Automation Layer**

* Built around **`browser-use`**:

  * Handles instruction parsing, reasoning, and Playwright control.
  * Can run in **headless** or **visible (debug)** mode.

* Supports:

  * Autonomous goal detection.
  * File downloads.
  * Screenshot capture.
  * Event hooks (step logging, on-error handlers).

* **Session Context Management:**

  * Each user has a persistent browser context (stored cookies, login).
  * Can reuse context for chained instructions.

---

### **C. Event Logging & Monitoring**

* **Real-time event streaming** from backend to frontend.
* Events contain:

  * `step_id`, `action`, `description`, `timestamp`, `screenshot_path`
* All actions logged in DB and linked to task.
* Used to populate:

  * Timeline UI
  * Replay system
  * Summary report

---

### **D. Clarification / Q&A System**

* When `browser-use` or the backend LLM detects ambiguity:

  * Pauses automation.
  * Sends clarification request to frontend.
  * Waits for user input before resuming.
* Stored as an **interactive chat session** associated with the task.

---

### **E. Frontend Architecture**

* **Main Views:**

  1. **Task Input Page**

     * Text input for instruction
     * Mode selector (headless/headful)
     * Submit button
  2. **Active Task View**

     * Live logs
     * Screenshot previews
     * Stop/Pause button
     * Chat box for clarifications
  3. **Task History View**

     * List of all completed tasks
     * Status badges
     * Buttons: ‚ÄúView‚Äù, ‚ÄúReplay‚Äù, ‚ÄúClone‚Äù
  4. **Task Details / Timeline**

     * Step-by-step visual history
     * Screenshots per action
     * Download summary/logs

* **Communication:**

  * REST API for CRUD operations.
  * WebSocket for live updates and chat.

---

### **F. Storage and File Handling**

* All screenshots and downloaded files stored with structured naming:

  ```
  /storage/
    /tasks/{task_id}/
      step_1_open.png
      step_2_click.png
      download_1.pdf
  ```
* DB stores only relative paths.
* Frontend fetches via authenticated API routes.

---

### **G. Replay System**

* Replays previous instruction with same parameters.
* Optionally reuses browser context.
* Logs are versioned for comparison between runs.

---


-